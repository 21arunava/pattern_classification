{
 "metadata": {
  "name": "",
  "signature": "sha256:2dd34dad465ea7079e43a9bc07fa231763c98391b94c669f2aad30305cd002c1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext watermark"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%watermark -d -v -p scikit-learn,matplotlib,numpy,pandas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "19/08/2014 \n",
        "\n",
        "CPython 3.4.1\n",
        "IPython 2.1.0\n",
        "\n",
        "scikit-learn 0.15.0b1\n",
        "matplotlib 1.3.1\n",
        "numpy 1.8.1\n",
        "pandas 0.14.0\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font size=\"1.5em\">[More information](https://github.com/rasbt/watermark) about the `watermark` magic command extension.</font>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<hr>\n",
      "I would be happy to hear your comments and suggestions. \n",
      "Please feel free to drop me a note via\n",
      "[twitter](https://twitter.com/rasbt), [email](mailto:bluewoodtree@gmail.com), or [google+](https://plus.google.com/+SebastianRaschka).\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introduction to naive Bayes classifiers - building a spam filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sections"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [Introduction](#Introduction)\n",
      "    - [Pattern classification and predictive modeling](#Pattern-classification-and-predictive-modeling)\n",
      "    - [A typical workflow for supervised learning](#A-typical-workflow-for-supervised-learning)\n",
      "    - [Naive Bayes classifier](#Naive-Bayes-classifier)\n",
      "    - [Text classification and spam filtering](#Text-classification-and-spam-filtering)\n",
      "- [The SMS Spam dataset](#The-SMS-Spam-dataset)\n",
      "    - [Label Encoder](#Label-Encoder)\n",
      "    - [Test and training datasets](#Preparing-the-test-and-training-dataset)\n",
      "    - [Feature Extraction: Word counts and Vectorizers](#Feature-Extraction:-Word-counts-and-Vectorizers)\n",
      "- [Multinomial naive Bayes classifier](#Multinomial-naive-Bayes-classifier)\n",
      "- [K-fold cross-validation](#K-fold-cross-validation)\n",
      "- [Training and evaluation](#Training-and-evaluation)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pattern classification and predictive modeling"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](../../Images/bayes_smsspam/supervised_learning_flowchart.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Naive Bayes classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- relationship between features and classes is based on Bayes' theorem (probabilities)\n",
      "- decision based on calculating posterior probabilities\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- relationship between features and classes is based on Bayes' theorem (probabilities)\n",
      "- decision based on calculating posterior probabilities\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Independence assumptions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation} P(\\omega \\mid \\pmb x) = \\frac{P(\\pmb x \\mid \\omega) \\cdot P(\\omega)}{P(\\pmb x)} \\end{equation}\n",
      "\n",
      "with\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation} \\text{posterior probability} = \\frac{\\text{class-conditional probability} \\cdot \\text{prior probibility}}{\\text{evidence}} \\end{equation}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation} P(\\omega_j \\mid \\pmb x_i) = \\frac{P(\\pmb x_i \\mid \\omega_j) \\cdot P(\\omega_j)}{P(\\pmb x_i)} \\end{equation}\n",
      "\n",
      "- *$i$ = 1, 2, ..., n* (samples)\n",
      "- *$j$ = 1, 2, ..., m* (class labels)\n",
      "\n",
      "- $\\omega_j$ = class $j$\n",
      "- $\\pmb x_i$ = features of sample $i$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- likelihood = class-conditional probability\n",
      "\n",
      "- prior can be estimated from training data (requires representative sample; independently drawn)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation} P(\\text{spam} \\mid \\text{words}) = P(\\text{words} \\mid \\text{spam}) \\cdot P(\\text{spam}) \\\\\n",
      "  P(\\text{ham} \\mid \\text{words}) = P(\\text{words} \\mid \\text{ham}) \\cdot P(\\text{ham})\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation} P(\\text{spam} \\, | \\, \\text{words}) >\n",
      "  P(\\text{ham} \\, | \\, \\text{words}) \n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Calculating the prior probabilities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- iid for samples\n",
      "- naive bayes: independent features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{matrix} P{(\\omega_j)} = \\frac{\\text{number of samples with } \\omega_j=1}{\\text{total number of samples}} \\end{matrix}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Calculating the class-conditional probabilities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bayes classifiers makes the important assumption that our samples are ***i.i.d.***  \n",
      "The abbreviation \"i.i.d.\" stands for \"independent and identically distributed\" and describes random variables that are independent from one another and are drawn from a similar probability distribution. Independence means that the probability of one observation does not affect the probability of another observation (e.g., time series and network graphs are not independent).  One popular example of \"i.i.d.\" variables would be the tossing of a coin: One coin toss does not affect the outcome of another coin toss, and the probability of the coin landing on either \"heads\" or \"tails\" is the same for every coin toss.  \n",
      "\n",
      "An additional (\"naive\") assumption is the \"conditional independence\" of the features, which allows us to estimate the class-conditional probabilities for a particular sample directly from the training data instead of evaluating all possibilities of x."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation} P(\\pmb x \\mid \\omega) = \\prod_{k=1}^{d} P(\\pmb x_k \\mid \\omega) \\end{equation}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To use an example from the field of text classification: If the conditional independence holds, the observation of a word \"peanut\" in a particular text should not increase or decrease the probability of observing a particular second word in the text, e.g., \"butter\". In practice, like just like in the preceding example indicates, the conditional independence assumption is often violated. However, naive Bayes classifiers are still known to perform well even under those violations (Zhang, Harry. 2004. \"[The Optimality of Naive Bayes.](http://www.aaai.org/Papers/FLAIRS/2004/Flairs04-097.pdf)\" AA 1 (2): 3)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Calculating the evidence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- evidence can be dropped (constant for every class)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Variants of the Naive Bayes model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have discussed the \"conditional independence\" assumption in the previous section about calculating the class-conditional probabilities. However, we haven't talked about the individual underlying probability distributions of the individual attributes, yet. \n",
      "Basically, there are three different variants of the naive Bayes classifier:\n",
      "\n",
      "- Gaussian naive Bayes\n",
      "- Multinomial naive Bayes\n",
      "- Bernoulli naive Bayes\n",
      "\n",
      "The terms \"Gaussian\", \"Multinomial\", and \"Bernoulli\" just describe how the attributes in the dataset are distributed in order to calculate the class-conditional probability $P(\\pmb x_i \\mid \\omega_j)$.\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Multinomial Naive Bayes - A toy example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us consider a simple toy example with the following training set:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](../../Images/bayes_smsspam/toy_dataset_1.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us assume this dataset consists of 2 classes: green circles and blue squares, and each sample has the two attributes: a letter and a plus or minus sign.\n",
      "\n",
      "$\\omega_1$ (class 1) = green circle  \n",
      "$\\omega_2$ (class 2) = blue square\n",
      "\n",
      "$\\pmb x$ (feature vector) = $[x_1, x_2], \\quad$  for $x_1 \\in \\{ A, B, C, D \\}, \\quad x_2 \\in \\{ +, - \\}$      \n",
      "\n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, if we were to classify a new sample:\n",
      "![](../../Images/bayes_smsspam/toy_dataset_2.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our decision could be formulated as:\n",
      "\n",
      "Classify sample as $\\omega_1$ (class 1, green circle) if   \n",
      "\n",
      "$P(\\omega_1 \\mid \\pmb x) \\geq P(\\omega_2 \\mid \\pmb x)$  \n",
      "\n",
      "else classify sample as $\\omega_2$ (class 2, green circle), where $\\pmb x$ = (A, +)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our **prior probabilities** could be calculated from the training set as follows:\n",
      "\n",
      "$P(\\omega_1) = \\frac{5}{12} = 0.42$    \n",
      "\n",
      "$P(\\omega_2) = \\frac{7}{12} = 0.58$    \n",
      "\n",
      "And the class-conditional probabilities (likelihoods):\n",
      "\n",
      "$P(\\pmb x \\mid \\omega_1) = P(\\text{\"A\"} \\mid \\omega_1) \\cdot P(\\text{\"+\"} \\mid \\omega_1) = \\frac{2}{5} \\cdot \\frac{2}{5} = 0.16$   \n",
      "\n",
      "$P(\\pmb x \\mid \\omega_2) = P(\\text{\"A\"} \\mid \\omega_2) \\cdot P(\\text{\"+\"} \\mid \\omega_2) = \\frac{3}{7} \\cdot \\frac{4}{7} = 0.24$  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And the posterior probabilities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$P(\\omega_1 \\mid \\pmb x) = P(\\pmb x \\mid \\omega_1) \\cdot P(\\omega_1) = 0.16  \\cdot  0.42 = 0.07$  \n",
      "\n",
      "$P(\\omega_2 \\mid \\pmb x) = P(\\pmb x \\mid \\omega_2) \\cdot P(\\omega_2) = 0.24  \\cdot  0.58 = 0.14$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And if we apply those values in our decision rule"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\text{If } P(\\omega_1 \\mid \\pmb x) \\geq P(\\omega_2 \\mid \\pmb x) \\Rightarrow \\omega_1 \\text{, else } \\omega_2 $  \n",
      "\n",
      "And since \n",
      "\n",
      "$\\Rightarrow 0.07 < 0.24$  \n",
      "\n",
      "$\\Rightarrow \\text{classify as } \\omega_2$  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Additive smoothening"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What happens if we have a sample that has the letter attribute \"C\"? Since the letter \"C\" doesn't occur in our training set, we would run into the problem of a class-conditional probability of 0, which will cause a 0 for the posterior probabilities.\n",
      "\n",
      "$P(\\omega_1 \\mid \\pmb x) = 0  \\cdot  0.42 = 0$  \n",
      "\n",
      "$P(\\omega_2 \\mid \\pmb x) = 0  \\cdot  0.58 = 0$  \n",
      "\n",
      "In this case, we could apply an additive smoothening term for our multinomial distribution to ensure that the class-conditional probability is non-zero. \n",
      "\n",
      "Considering our general equation for Multinomial Bayes  \n",
      "$\\hat{\\theta}_{\\omega i} = \\frac{ N_{\\omega i} + \\alpha}{N_{\\omega} + \\alpha n}$\n",
      "\n",
      "Two common variants of additive smoothening are the so-called Lidstone smoothening ($\\alpha<1$) or  Laplace smoothening ($\\alpha=1$).\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Continuous variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The naive Bayes model is not restricted to categorical data like in our example above, but we can also train a naive Bayes classifier on continuous data. The Iris flower data set would be a simple example for a supervised classification task with continuous features: The Iris dataset contains widths and lengths of petals and sepals measured in centimeters.  \n",
      "One strategy for dealing with continuous data in naive Bayes classification would be to discretize the features and form distinct categories. A more common approach is to use a Gaussian or Multinomial kernel to calculate the class-conditional probabilities.\n",
      "\n",
      "For the Iris example, we could assume that the probability distribution for the features  follow a normal  (Gaussian)  distribution:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{equation} P(x_{ik} \\mid \\omega) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_{\\omega}}} \\exp\\left(-\\frac{(x_{ik} - \\mu_{\\omega})^2}{2\\sigma^2_{\\omega}}\\right) \\end{equation}\n",
      "\n",
      "\\begin{equation} P(\\pmb x_i \\mid \\omega) = \\prod_{k=1}^{d} P(\\pmb x_{ik} \\mid \\omega) \\end{equation}"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Eager and lazy learning algorithms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Being an \"eager learner\", one of the advantages of naive classifiers is that they are generally fast in classifying new instances.   \n",
      "The concept of \"eager learners\" describes learning algorithms that learn a model from a training dataset as soon as the data becomes available. Once the model is learned, the training data does not have to be re-evaluated in order to make a new prediction. For \"eager learners\", the computationally most expensive step is the model building, and the classification of new instances is relatively fast.  \n",
      "\"Lazy learners\", however, memorize and re-evaluate the training dataset for prediciting the class label of a new instance. The advantage of \"lazy learning\" is that the model building (training) phase is relatively fast. On the other hand, the acutal prediction is typically slower compared to \"eager learners\" due to the evaluation of the training data. An example of a \"lazy learner\" would be a k-nearest neighbor algorithm. If a new instance is encountered, the algorithm would evaluate the k-nearest neighbors in order to decide upon a class label for the new instance, e.g., via the majority rule (= assign the class label that occurs most frequently amongst the k-nearest neighbors)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Text classification and spam filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As mentioned above, text classification\n",
      "\n",
      "In our example, we will define the two class labels \"spam\" and \"ham\" (= not \"spam\") in order to group SMS text messages based on their contents. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The SMS Spam dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv(\n",
      "        'https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/sms_spam_collection.txt', \n",
      "        sep='\\t', \n",
      "        header=None)\n",
      "\n",
      "df.columns = ['class', 'text']\n",
      "\n",
      "df.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/sebastian/miniconda3/envs/py34/lib/python3.4/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>class</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> spam</td>\n",
        "      <td> Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  ham</td>\n",
        "      <td> Go until jurong point, crazy.. Available only ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  ham</td>\n",
        "      <td>                     Ok lar... Joking wif u oni...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "  class                                               text\n",
        "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
        "1   ham  Go until jurong point, crazy.. Available only ...\n",
        "2   ham                      Ok lar... Joking wif u oni..."
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.tail(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>class</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>5569</th>\n",
        "      <td> ham</td>\n",
        "      <td> Pity, * was in mood for that. So...any other s...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5570</th>\n",
        "      <td> ham</td>\n",
        "      <td> The guy did some bitching but I acted like i'd...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5571</th>\n",
        "      <td> ham</td>\n",
        "      <td>                        Rofl. Its true to its name</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "     class                                               text\n",
        "5569   ham  Pity, * was in mood for that. So...any other s...\n",
        "5570   ham  The guy did some bitching but I acted like i'd...\n",
        "5571   ham                         Rofl. Its true to its name"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "plt.pie(\n",
      "    (len(df[df['class'] == 'spam']), len(df[df['class'] == 'ham'])),\n",
      "    labels=('spam','ham'),\n",
      "    shadow=True,\n",
      "    colors=('yellowgreen', 'lightskyblue'),\n",
      "    explode=(0,0.15),\n",
      "    startangle=90,\n",
      "    autopct='%1.1f%%',\n",
      "    )\n",
      "plt.legend(fancybox=True)\n",
      "plt.axis('equal')\n",
      "plt.tight_layout()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEjCAYAAABnxZXbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x106b10780>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Label Encoder"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "X = df['text'].values \n",
      "y = df['class'].values\n",
      "\n",
      "print('before: %s ...' %y[:5])\n",
      "\n",
      "le = LabelEncoder()\n",
      "y = le.fit_transform(y)\n",
      "\n",
      "print('after: %s ...' %y[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "before: ['spam' 'ham' 'ham' 'ham' 'ham'] ...\n",
        "after: [1 0 0 0 0] ...\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test and training datasets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature Extraction: Word counts and Vectorizers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
      "\n",
      "vec = CountVectorizer().fit(['Hello World, this is a test!'])\n",
      "data1 = vec.transform(['This is a test'])\n",
      "data2 = vec.transform(['Hello World'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Features:\\n%s' %vec.get_feature_names())\n",
      "print(\"\\nText 'This is a test':\\n%s\" %data1.toarray())\n",
      "print(\"\\nText 'Hello World':\\n%s\" %data2.toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features:\n",
        "['hello', 'is', 'test', 'this', 'world']\n",
        "\n",
        "Text 'This is a test':\n",
        "[[0 1 1 1 0]]\n",
        "\n",
        "Text 'Hello World':\n",
        "[[1 0 0 0 1]]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"Stop Words are words which do not contain important significance to be used in Search Queries. Usually these words are filtered out from search queries because they return vast amount of unnecessary information. A better definition is provided below:\n",
      "\n",
      "\u201cWords that do not appear in the index in a particular database because they are either insignificant (i.e., articles, prepositions) or so common that the results would be higher than the system can handle (as in the case of IUCAT where terms such as United States or Department are stop words in keyword searching.) Stop words vary from system to system. Also, some systems will merely ignore stop words where use of stop words in other systems will result in retrieving zero hits. \u201d\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
      "\n",
      "vec = CountVectorizer().fit(X)\n",
      "allwords = vec.transform(X)\n",
      "spam = vec.transform(X[y==1])\n",
      "ham = vec.transform(X[y==0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_col_sum = np.sum(spam.toarray(), axis=0)\n",
      "spam_count_sorted = sorted([(count,index) for (index,count) in enumerate(spam_col_sum)], reverse=True)\n",
      "\n",
      "ham_col_sum = np.sum(ham.toarray(), axis=0)\n",
      "ham_count_sorted = sorted([(count,index) for (index,count) in enumerate(ham_col_sum)], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\n",
      "\n",
      "spam_labels = [vec.get_feature_names()[i[1]] for i in spam_count_sorted[:10]]\n",
      "ham_labels = [vec.get_feature_names()[i[1]] for i in ham_count_sorted[:10]]\n",
      "\n",
      "# plot bars\n",
      "x_pos = list(range(len(spam_labels)))\n",
      "\n",
      "ax1.bar(x_pos, \n",
      "        [i[0]/np.sum(spam_col_sum) for i in spam_count_sorted[:10]], \n",
      "        align='center', \n",
      "        alpha=0.5)\n",
      "\n",
      "ax2.bar(x_pos, \n",
      "        [i[0]/np.sum(ham_col_sum) for i in ham_count_sorted[:10]], \n",
      "        align='center', \n",
      "        alpha=0.5)\n",
      "\n",
      "# set axes labels and title\n",
      "ax1.set_ylabel('frequency in total spam text corpus')\n",
      "ax1.set_xticklabels(x_pos, spam_labels)\n",
      "\n",
      "ax2.set_xticklabels(x_pos, ham_labels)\n",
      "ax2.set_ylabel('frequency in total ham text corpus')\n",
      "\n",
      "for ax in (ax1,ax2):\n",
      "    # hiding axis ticks\n",
      "    ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
      "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
      "\n",
      "    # remove axis spines\n",
      "    ax.spines[\"top\"].set_visible(False)  \n",
      "    ax.spines[\"right\"].set_visible(False) \n",
      "    ax.spines[\"bottom\"].set_visible(False) \n",
      "    ax.spines[\"left\"].set_visible(False)\n",
      "\n",
      "plt.tight_layout()\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAEaCAYAAADzO0ZoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEdGX/j8TH0On8HzoHQAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10bab9438>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Top 10 spam words:\\n')\n",
      "for i in spam_count_sorted[:10]:\n",
      "    print('%s (%sx)' %(vec.get_feature_names()[i[1]], i[0]))\n",
      "    \n",
      "print('\\nTop 10 ham words:\\n')\n",
      "for i in ham_count_sorted[:10]:\n",
      "    print('%s (%sx)' %(vec.get_feature_names()[i[1]], i[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top 10 spam words:\n",
        "\n",
        "to (691x)\n",
        "call (355x)\n",
        "you (297x)\n",
        "your (264x)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "free (224x)\n",
        "the (206x)\n",
        "for (204x)\n",
        "now (199x)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "or (188x)\n",
        "txt (163x)\n",
        "\n",
        "Top 10 ham words:\n",
        "\n",
        "you (1948x)\n",
        "to (1562x)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the (1133x)\n",
        "and (858x)\n",
        "in (823x)\n",
        "me (777x)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "my (754x)\n",
        "is (739x)\n",
        "it (718x)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "that (560x)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"TfidfVectorizer works like the CountVectorizer, but with a more advanced calculation called Term Frequency Inverse Document Frequency (TF-IDF). This is a statistic for measuring the importance of a word in a document or corpus. Intuitively, it looks for words that are more frequent in the current document, compared with their frequency in the whole corpus of documents. You can see this as a way to normalize the results and avoid words that are too frequent, and thus not useful to characterize the instances.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"CountVectorizer basically creates a dictionary of words from the text corpus. Then, each instance is converted to a vector of numeric features where each element will be the count of the number of times a particular word appears in the document.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multinomial naive Bayes classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "K-fold cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The model is most commonly evaluated by the empirical error rate, which is calculated by the number of correct classifications (i.e., false postives and false negatives) divided by the number of total classifications. Inversly, the accuracy of a model is calculated by true postives and true negatives / number of total classifications or simply 1-error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is important to note that the test set should only be used once for evaluating the prediction error of a classifier after training it on the training dataset; repetitive evaluations of different models using the same test dataset would be prone to overfitting.\n",
      "A common approach to compare and evaluate different pre-processing techniques and models is cross-validation. Here, we will use a variant called \"k-fold cross-validation\" in order to compare different preprocessing steps and demonstrate the usefulness of a Pipeline.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_1 = Pipeline([\n",
      "    ('vectorizer', CountVectorizer()),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_2 = Pipeline([\n",
      "    ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_3 = Pipeline([\n",
      "    ('vectorizer', CountVectorizer(ngram_range=(1,3))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_4 = Pipeline([\n",
      "    ('vectorizer', TfidfVectorizer()),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_5 = Pipeline([\n",
      "    ('vectorizer', TfidfVectorizer(ngram_range=(1,2))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_6 = Pipeline([\n",
      "    ('vectorizer', TfidfVectorizer(ngram_range=(1,3))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec = CountVectorizer(stop_words=\"english\").fit(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "\n",
      "# Constructing the k-fold cross validation iterator (k=10)  \n",
      "\n",
      "cv = KFold(n=X_train.shape[0],  # total number of samples\n",
      "           n_folds=10,           # number of folds the dataset is divided into\n",
      "           random_state=12345)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ACC = (TP + TN) / (TP+TN + FP+FN)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acc_scores = [\n",
      "    cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
      "            for clf in [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6]\n",
      "    ]\n",
      "\n",
      "for score,label in zip(acc_scores, \n",
      "                       ['CountVectorizer unigram', \n",
      "                        'CountVectorizer bigram',\n",
      "                        'CountVectorizer trigram', \n",
      "                        'TfidfVectorizer unigram', \n",
      "                        'TfidfVectorizer bigram',\n",
      "                        'TfidfVectorizer trigram'\n",
      "                        ]\n",
      "                       ):\n",
      "    print(\"Accuracy: {:.2%} (+/- {:.2%}), {:}\".format(score.mean(), score.std(), label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 98.46% (+/- 0.77%), CountVectorizer unigram\n",
        "Accuracy: 98.44% (+/- 0.67%), CountVectorizer bigram\n",
        "Accuracy: 98.36% (+/- 0.69%), CountVectorizer trigram\n",
        "Accuracy: 95.51% (+/- 1.39%), TfidfVectorizer unigram\n",
        "Accuracy: 94.13% (+/- 1.68%), TfidfVectorizer bigram\n",
        "Accuracy: 93.56% (+/- 1.77%), TfidfVectorizer trigram\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table cellspacing=\"0\" border=\"0\">\n",
      "    <colgroup width=\"60\"></colgroup>\n",
      "    <colgroup span=\"4\" width=\"82\"></colgroup>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" colspan=2 rowspan=2 height=\"44\" align=\"center\" bgcolor=\"#FFFFFF\"><b><font face=\"Helvetica\" size=4><br></font></b></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" colspan=3 align=\"center\" bgcolor=\"#FFFFFF\"><b><font face=\"Helvetica\" size=4>predicted class</font></b></td>\n",
      "        </tr>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>0 (=Ham)</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>1 (=Spam)</font></td>\n",
      "\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" rowspan=3 height=\"116\" align=\"center\" bgcolor=\"#F6F6F6\"><b><font face=\"Helvetica\" size=4>true class</font></b></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>0 (=Ham)</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#99FFCC\"><font face=\"Helvetica\" size=4>True Negative (TN)</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#F6F6F6\"><font face=\"Helvetica\" size=4>False Positive (FP)</font></td>\n",
      "\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>1 (=Spam)</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#FFFFFF\"><font face=\"Helvetica\" size=4>False Negative (FN)</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#99FFCC\"><font face=\"Helvetica\" size=4>True Positive (TP)</font></td>\n",
      "\n",
      "    </tr>\n",
      "\n",
      "</table>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute the precision\n",
      "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PREC tp / (tp + fp)\n",
      "\"The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\"\n",
      "\"\"of all things that were labeled as spam, how many were actually spam?\"\"\n",
      "\n",
      "RECALL tp / (tp + fn)\n",
      "\"recall is intuitively the ability of the classifier to find all the positive samples.\"\n",
      "\"\"of all the things that are truly spam, how many did we label?\"\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prec_recall_scores = [\n",
      "    (cross_val_score(clf, X_train, y_train, cv=cv, scoring='precision'),\n",
      "    cross_val_score(clf, X_train, y_train, cv=cv, scoring='recall'))\n",
      "            for clf in [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6]\n",
      "    ]\n",
      "\n",
      "for score,label in zip(prec_recall_scores, \n",
      "                       ['CountVectorizer unigram', \n",
      "                        'CountVectorizer bigram',\n",
      "                        'CountVectorizer trigram', \n",
      "                        'TfidfVectorizer unigram', \n",
      "                        'TfidfVectorizer bigram',\n",
      "                        'TfidfVectorizer trigram'\n",
      "                        ]\n",
      "                       ):\n",
      "    print(\"Precision: {:.2%} (+/- {:.2%}), {:}\".format(score[0].mean(), score[0].std(), label))\n",
      "    print(\"Recall: {:.2%} (+/- {:.2%}), {:}\\n\".format(score[1].mean(), score[1].std(), label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_7 = Pipeline([\n",
      "    ('vectorizer', CountVectorizer(ngram_range=(1,2), stop_words='english')),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_8 = Pipeline([\n",
      "    ('vectorizer', TfidfVectorizer(ngram_range=(1,2), stop_words='english')),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prec_recall_scores = [\n",
      "    (cross_val_score(clf, X_train, y_train, cv=cv, scoring='precision'),\n",
      "     cross_val_score(clf, X_train, y_train, cv=cv, scoring='recall'))\n",
      "            for clf in [clf_2, clf_7, clf_5, clf_8]\n",
      "    ]\n",
      " \n",
      "for score,label in zip(prec_recall_scores, \n",
      "                       [\n",
      "                        'CountVectorizer bigram',\n",
      "                        'CountVectorizer bigram w. stop words',\n",
      "                        'TfidfVectorizer bigram',\n",
      "                        'TfidfVectorizer bigram w. stop words',\n",
      "                        ]\n",
      "                       ):\n",
      "    print(\"Precision: {:.2%} (+/- {:.2%}), {:}\".format(score[0].mean(), score[0].std(), label))\n",
      "    print(\"Recall: {:.2%} (+/- {:.2%}), {:}\\n\".format(score[1].mean(), score[1].std(), label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Precision: 99.25% (+/- 1.21%), CountVectorizer bigram\n",
        "Recall: 88.99% (+/- 3.90%), CountVectorizer bigram\n",
        "\n",
        "Precision: 97.60% (+/- 1.91%), CountVectorizer bigram w. stop words\n",
        "Recall: 91.48% (+/- 4.24%), CountVectorizer bigram w. stop words\n",
        "\n",
        "Precision: 100.00% (+/- 0.00%), TfidfVectorizer bigram\n",
        "Recall: 55.56% (+/- 6.28%), TfidfVectorizer bigram\n",
        "\n",
        "Precision: 100.00% (+/- 0.00%), TfidfVectorizer bigram w. stop words\n",
        "Recall: 68.58% (+/- 6.02%), TfidfVectorizer bigram w. stop words\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Training and evaluation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_2.fit(X_train, y_train)\n",
      "pred = clf_2.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "\n",
      "fig = plt.figure(figsize=(6,6))\n",
      "ax = plt.subplot(111) \n",
      "\n",
      "cax = ax.matshow(cm)\n",
      "\n",
      "fig.colorbar(cax)\n",
      "\n",
      "ax.set_ylabel('True label')\n",
      "ax.set_xlabel('Predicted label')\n",
      "ax.set_xticklabels(['', 'ham', 'spam'])\n",
      "ax.set_yticklabels(['', 'ham', 'spam'])\n",
      "\n",
      "plt.title('Confusion matrix')\n",
      "plt.show()\n",
      "\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'y_pred' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-22-6b3cf4643abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
      "\n",
      "for score in [accuracy_score, recall_score, precision_score]:\n",
      "    print('%s: %s' %(score.__name__, score(y_test, y_pred)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "ROC curve"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[[back to top](#Sections)]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "probas_ = clf_2.fit(X_train, y_train).predict_proba(X_test)\n",
      "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1], pos_label=1)\n",
      "roc_auc = auc(fpr, tpr)\n",
      "\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver operating characteristic (ROC)')\n",
      "\n",
      "plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}