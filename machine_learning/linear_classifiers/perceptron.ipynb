{
 "metadata": {
  "name": "",
  "signature": "sha256:bf55dc0ee5fe54715eb87fb7b7f9320fdce28b77f8a4b4f4a1c7fa327aa01034"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "... in progress"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Linear binary classification: how perceptrons work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Linear binary classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- d-dimensional sample vector $\\textbf{x} = [x_1, ..., x_d]$  \n",
      "- d-dimensional weight vector $\\textbf{w} = [w_1, ..., w_d]^T$   \n",
      "- threshold $\\theta$ (scalar)\n",
      "- class labels $\\omega_j$ ( $j \\in \\{0,1\\}$ )"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$y' = \\textbf{w.x} $ \n",
      "\n",
      "$\\textbf{w.x} > \\theta \\rightarrow 1$   \n",
      "$\\textbf{w.x} < \\theta \\rightarrow -1$   \n",
      "$\\textbf{w.x} = \\theta \\rightarrow \\text{always \"misclassified\"}$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Goal: Find $\\theta$ and $\\textbf{w}$ so that all samples are separated by the hyperplane (either below -1, or above +1)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Initialize the weight vector w to all 0\u2019s.\n",
      "2. Pick a learning-rate parameter \u03b7, which is a small, positive real number. The choice of \u03b7 affects the convergence of the perceptron. If \u03b7 is too small, then convergence is slow; if it is too big, then the decision boundary will \u201cdance around\u201d and again will converge slowly, if at all.\n",
      "3. Consider each training example t = (x, y) in turn.\n",
      "\n",
      "\n",
      "- (a) Let y\u2032 = w.x.\n",
      "- (b) If y\u2032 and y have the same sign, then do nothing; t is properly classi- fied.\n",
      "- (c) However, if y\u2032 and y have different signs, or y\u2032 = 0, replace w by w + \u03b7yx. That is, adjust w slightly in the direction of x."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Columns represent features, rows represent samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "# samples\n",
      "x = np.array([[1, 1, 0, 1, 1],[0, 0, 1, 1, 0], [0, 1, 1, 0, 0], [1, 0, 0, 1, 0], [1, 0, 1, 0, 1], [1, 0, 1, 1, 0]])\n",
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "array([[1, 1, 0, 1, 1],\n",
        "       [0, 0, 1, 1, 0],\n",
        "       [0, 1, 1, 0, 0],\n",
        "       [1, 0, 0, 1, 0],\n",
        "       [1, 0, 1, 0, 1],\n",
        "       [1, 0, 1, 1, 0]])"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ground truth class labels\n",
      "y = np.array([1, -1, 1, -1, 1, -1])\n",
      "\n",
      "# learning rate\n",
      "eta = 0.5\n",
      "\n",
      "# weights\n",
      "w = np.array([0,0,0,0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Weights are updated if $y$ (ground truth class label) and $y'$ (predicted class label) have opposite signs by\n",
      "\n",
      "$\\textbf{w} = \\textbf{w} + \\eta\\cdot y \\cdot x$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# first sample \n",
      "if w.dot(x[0,:]) <= 0:\n",
      "    print('update weight:')\n",
      "    print(w + (eta)*(+1)*x[0,:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "update weight:\n",
        "[ 0.5  0.5  0.   0.5  0.5]\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# update weights if y (ground truth class label) and y' have opposite signs\n",
      "\n",
      "w = np.array([0,0,0,0,0])\n",
      "\n",
      "for i in range(x.shape[0]):\n",
      "    \n",
      "    y_pred = w.dot(x[i,:])\n",
      "    if (y[i] < 0 and y_pred >= 0) or \\\n",
      "       (y[i] > 0 and y_pred <= 0):\n",
      "            \n",
      "        w = w + (eta)*y[i]*x[i,:]\n",
      "        \n",
      "print('new weight vector: \\n%s' %w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "new weight vector: \n",
        "[ 0.   1.   0.  -0.5  0.5]\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#classify\n",
      "\n",
      "def classify(x):\n",
      "    y = []\n",
      "    for i in range(x.shape[0]):\n",
      "        y_pred = w.dot(x[i,:])\n",
      "        if y_pred > 0:\n",
      "            y.append(1)\n",
      "        elif y_pred < 0:\n",
      "            y.append(-1)\n",
      "        else:\n",
      "            y.append(0)\n",
      "    return np.array(y)\n",
      "\n",
      "y_pred = classify(x)\n",
      "\n",
      "print('true classes:      %s' %y)\n",
      "print('predicted classes: %s' %y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "true classes:      [ 1 -1  1 -1  1 -1]\n",
        "predicted classes: [ 1 -1  1 -1  1 -1]\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "true_positives = sum(y[:] == y_pred[:])\n",
      "accuracy = true_positives / x.shape[0]\n",
      "print('prediction accuracy: {:2.2%}'.format(accuracy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "prediction accuracy: 100.00%\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Convergence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Terminate after a fixed number of rounds.\n",
      "2. Terminate when the number of misclassified training points stops chang- ing.\n",
      "3. Withhold a test set from the training data, and after each round, run the perceptron on the test data. Terminate the algorithm when the number of errors on the test set stops changing.\n",
      "\n",
      "\n",
      "Another technique that will aid convergence is to lower the training rate as the number of rounds increases. For example, we could allow the training rate \u03b7 to start at some initial \u03b70 and lower it to \u03b70/(1 + ct) after the tth round, where c is some small constant."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic Perceptron Algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Perceptron(object):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self.acc = 0.0\n",
      "        \n",
      "    def train(self, x, y, max_rounds=1, learning_rate=0.5):\n",
      "        self.n = x.shape[0]\n",
      "        self.d = x.shape[1]\n",
      "        self.w = np.zeros((1, self.d))\n",
      "        self.eta = learning_rate\n",
      "        self.y_pred = np.zeros((1, self.n))\n",
      "        \n",
      "        previous_acc = self.acc\n",
      "        for i in range(max_rounds):\n",
      "            for i in range(self.n):\n",
      "                y_pred = self.w.dot(x[i,:])\n",
      "                if (y[i] < 0 and y_pred >= 0) or \\\n",
      "                   (y[i] > 0 and y_pred <= 0):\n",
      "            \n",
      "                    self.w = self.w + (self.eta)*y[i]*x[i,:]\n",
      "            \n",
      "            # stop if accuracy didn't change\n",
      "            self._accuracy(x, y)\n",
      "            if self.acc == previous_acc:\n",
      "                break\n",
      "            else:\n",
      "                previous_acc = self.acc\n",
      "                \n",
      "    def print_accuracy(self, x, y):\n",
      "        self._accuracy(x, y)\n",
      "        print('prediction accuracy: {:2.2%}'.format(self.acc))\n",
      "    \n",
      "    def _accuracy(self, x, y):\n",
      "        self.y_pred = self._classify(x)\n",
      "        true_positives = sum(y[:] == self.y_pred[:])\n",
      "        self.acc = true_positives / self.n\n",
      "        \n",
      "    def _classify(self, x):\n",
      "        y_pred = []\n",
      "        for i in range(x.shape[0]):\n",
      "            y_p = w.dot(x[i,:])\n",
      "            if y_p > 0:\n",
      "                y_pred.append(1)\n",
      "            elif y_p < 0:\n",
      "                y_pred.append(-1)\n",
      "            else:\n",
      "                y_pred.append(0)\n",
      "        return np.array(y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perc = Perceptron()\n",
      "perc.train(x, y, max_rounds=10, learning_rate=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perc.print_accuracy(x, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "prediction accuracy: 100.00%\n"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perc._classify(np.array([1,1,1,0,1]).reshape(1,5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 189,
       "text": [
        "array([1])"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Winnow Algorithm"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}