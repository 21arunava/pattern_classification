{
 "metadata": {
  "name": "",
  "signature": "sha256:394cac6949d4361c99c4e7e57eb9ed1b543d531c1e4dbe0052b047ddbbb3d7d7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"CountVectorizer basically creates a dictionary of words from the text corpus. Then, each instance is converted to a vector of numeric features where each element will be the count of the number of times a particular word appears in the document.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv(\n",
      "        'https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/sms_spam_collection.txt', \n",
      "        sep='\\t', \n",
      "        header=None)\n",
      "\n",
      "df.columns = ['class', 'text']\n",
      "\n",
      "df.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>class</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  ham</td>\n",
        "      <td> Go until jurong point, crazy.. Available only ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  ham</td>\n",
        "      <td>                     Ok lar... Joking wif u oni...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> spam</td>\n",
        "      <td> Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "  class                                               text\n",
        "0   ham  Go until jurong point, crazy.. Available only ...\n",
        "1   ham                      Ok lar... Joking wif u oni...\n",
        "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.tail(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>class</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>5569</th>\n",
        "      <td> ham</td>\n",
        "      <td> Pity, * was in mood for that. So...any other s...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5570</th>\n",
        "      <td> ham</td>\n",
        "      <td> The guy did some bitching but I acted like i'd...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5571</th>\n",
        "      <td> ham</td>\n",
        "      <td>                        Rofl. Its true to its name</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "     class                                               text\n",
        "5569   ham  Pity, * was in mood for that. So...any other s...\n",
        "5570   ham  The guy did some bitching but I acted like i'd...\n",
        "5571   ham                         Rofl. Its true to its name"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"TfidfVectorizer works like the CountVectorizer, but with a more advanced calculation called Term Frequency Inverse Document Frequency (TF-IDF). This is a statistic for measuring the importance of a word in a document or corpus. Intuitively, it looks for words that are more frequent in the current document, compared with their frequency in the whole corpus of documents. You can see this as a way to normalize the results and avoid words that are too frequent, and thus not useful to characterize the instances.\""
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test and Training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "X = df['text'].values \n",
      "y = df['class'].values\n",
      "\n",
      "print('before: %s ...' %y[:5])\n",
      "\n",
      "le = LabelEncoder()\n",
      "y = le.fit_transform(y)\n",
      "\n",
      "print('after: %s ...' %y[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "before: ['ham' 'ham' 'spam' 'ham' 'ham'] ...\n",
        "after: [0 0 1 0 0] ...\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "K-fold cross-validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_1 = Pipeline([\n",
      "    ('vectorizer', CountVectorizer()),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_2 = Pipeline([\n",
      "    ('vectorizer', CountVectorizer(ngram_range=(1,2))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_3 = Pipeline([\n",
      "    ('vectorizer', CountVectorizer(ngram_range=(1,3))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_4 = Pipeline([\n",
      "    ('vectorizer', TfidfVectorizer()),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_5 = Pipeline([\n",
      "    ('vectorizer', TfidfVectorizer(ngram_range=(1,2))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])\n",
      "\n",
      "clf_6 = Pipeline([\n",
      "    ('vectorizer', TfidfVectorizer(ngram_range=(1,3))),\n",
      "    ('classifier', MultinomialNB()),\n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "\n",
      "# Constructing the k-fold cross validation iterator (k=10)  \n",
      "\n",
      "cv = KFold(n=X_train.shape[0],  # total number of samples\n",
      "           n_folds=10,           # number of folds the dataset is divided into\n",
      "           random_state=12345)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ACC = (TP + TN) / (TP+TN + FP+FN)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acc_scores = [\n",
      "    cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
      "            for clf in [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6]\n",
      "    ]\n",
      "\n",
      "for score,label in zip(acc_scores, \n",
      "                       ['CountVectorizer unigram', \n",
      "                        'CountVectorizer bigram',\n",
      "                        'CountVectorizer trigram', \n",
      "                        'TfidfVectorizer unigram', \n",
      "                        'TfidfVectorizer bigram',\n",
      "                        'TfidfVectorizer trigram'\n",
      "                        ]\n",
      "                       ):\n",
      "    print(\"Accuracy: {:.2%} (+/- {:.2%}), {:}\".format(score.mean(), score.std(), label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 98.35% (+/- 0.70%), CountVectorizer unigram\n",
        "Accuracy: 98.50% (+/- 0.88%), CountVectorizer bigram\n",
        "Accuracy: 98.30% (+/- 1.04%), CountVectorizer trigram\n",
        "Accuracy: 95.21% (+/- 1.73%), TfidfVectorizer unigram\n",
        "Accuracy: 93.66% (+/- 1.68%), TfidfVectorizer bigram\n",
        "Accuracy: 92.88% (+/- 1.72%), TfidfVectorizer trigram\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table cellspacing=\"0\" border=\"0\">\n",
      "    <colgroup width=\"60\"></colgroup>\n",
      "    <colgroup span=\"4\" width=\"82\"></colgroup>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" colspan=2 rowspan=2 height=\"44\" align=\"center\" bgcolor=\"#FFFFFF\"><b><font face=\"Helvetica\" size=4><br></font></b></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" colspan=3 align=\"center\" bgcolor=\"#FFFFFF\"><b><font face=\"Helvetica\" size=4>predicted class</font></b></td>\n",
      "        </tr>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>Spam</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>Ham</font></td>\n",
      "\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" rowspan=3 height=\"116\" align=\"center\" bgcolor=\"#F6F6F6\"><b><font face=\"Helvetica\" size=4>true class</font></b></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>Spam</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#99FFCC\"><font face=\"Helvetica\" size=4>True Positive (TP)</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#F6F6F6\"><font face=\"Helvetica\" size=4>False Negative (FN)</font></td>\n",
      "\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#EEEEEE\"><font face=\"Helvetica\" size=4>Ham</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#FFFFFF\"><font face=\"Helvetica\" size=4>False Positive (FP)</font></td>\n",
      "        <td style=\"border-top: 1px solid #c1c1c1; border-bottom: 1px solid #c1c1c1; border-left: 1px solid #c1c1c1; border-right: 1px solid #c1c1c1\" align=\"left\" bgcolor=\"#99FFCC\"><font face=\"Helvetica\" size=4>True Negative (TN)</font></td>\n",
      "\n",
      "    </tr>\n",
      "\n",
      "</table>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute the precision\n",
      "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PREC tp / (tp + fp)\n",
      "\"The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\"\n",
      "\"\"of all things that were labeled as spam, how many were actually spam?\"\"\n",
      "\n",
      "RECALL tp / (tp + fn)\n",
      "\"recall is intuitively the ability of the classifier to find all the positive samples.\"\n",
      "\"\"of all the things that are truly spam, how many did we label?\"\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prec_recall_scores = [\n",
      "    (cross_val_score(clf, X_train, y_train, cv=cv, scoring='precision'),\n",
      "    cross_val_score(clf, X_train, y_train, cv=cv, scoring='recall'))\n",
      "            for clf in [clf_1, clf_2, clf_3, clf_4, clf_5, clf_6]\n",
      "    ]\n",
      "\n",
      "for score,label in zip(prec_recall_scores, \n",
      "                       ['CountVectorizer unigram', \n",
      "                        'CountVectorizer bigram',\n",
      "                        'CountVectorizer trigram', \n",
      "                        'TfidfVectorizer unigram', \n",
      "                        'TfidfVectorizer bigram',\n",
      "                        'TfidfVectorizer trigram'\n",
      "                        ]\n",
      "                       ):\n",
      "    print(\"Precision: {:.2%} (+/- {:.2%}), {:}\".format(score[0].mean(), score[0].std(), label))\n",
      "    print(\"Recall: {:.2%} (+/- {:.2%}), {:}\\n\".format(score[1].mean(), score[1].std(), label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Precision: 96.51% (+/- 2.81%), CountVectorizer unigram\n",
        "Recall: 91.04% (+/- 4.79%), CountVectorizer unigram\n",
        "\n",
        "Precision: 99.74% (+/- 0.77%), CountVectorizer bigram\n",
        "Recall: 89.37% (+/- 4.83%), CountVectorizer bigram\n",
        "\n",
        "Precision: 99.74% (+/- 0.77%), CountVectorizer trigram\n",
        "Recall: 87.84% (+/- 5.86%), CountVectorizer trigram\n",
        "\n",
        "Precision: 100.00% (+/- 0.00%), TfidfVectorizer unigram\n",
        "Recall: 64.32% (+/- 7.62%), TfidfVectorizer unigram\n",
        "\n",
        "Precision: 100.00% (+/- 0.00%), TfidfVectorizer bigram\n",
        "Recall: 52.10% (+/- 5.87%), TfidfVectorizer bigram\n",
        "\n",
        "Precision: 100.00% (+/- 0.00%), TfidfVectorizer trigram\n",
        "Recall: 46.13% (+/- 4.50%), TfidfVectorizer trigram\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 60
    }
   ],
   "metadata": {}
  }
 ]
}